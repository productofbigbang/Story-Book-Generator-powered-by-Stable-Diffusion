{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiPcMd4iPo40"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.schema import Document\n",
        "from langgraph.graph import END, StateGraph\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import pypdf\n",
        "import docx2txt\n",
        "import json\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the language model\n",
        "GROQ_LLM = ChatGroq(model=\"llama3-70b-8192\")\n",
        "\n",
        "# Define the graph state\n",
        "class GraphState(TypedDict):\n",
        "    research_topic: str\n",
        "    idea_nodes: List[str]\n",
        "    research_questions: List[str]\n",
        "    hypothesis_nodes: List[str]\n",
        "    literature_nodes: List[str]\n",
        "    methodology_nodes: List[str]\n",
        "    significance_nodes: List[str]\n",
        "    ethical_considerations: List[str]\n",
        "    timeline_and_budget: str\n",
        "    final_proposal: str\n",
        "    num_steps: int\n",
        "    extracted_data: List[str]\n",
        "    rag_context: str\n",
        "\n"
      ],
      "metadata": {
        "id": "CYhGCi-aQBXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        pdf_reader = pypdf.PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text()\n",
        "    return text\n",
        "\n",
        "# Function to extract text from Word document\n",
        "def extract_text_from_docx(file_path):\n",
        "    return docx2txt.process(file_path)\n",
        "\n",
        "# Function to process documents and create vector store\n",
        "def process_documents(file_paths):\n",
        "    texts = []\n",
        "    for file_path in file_paths:\n",
        "        if file_path.endswith('.pdf'):\n",
        "            texts.append(extract_text_from_pdf(file_path))\n",
        "        elif file_path.endswith('.docx'):\n",
        "            texts.append(extract_text_from_docx(file_path))\n",
        "\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    docs = text_splitter.create_documents(texts)\n",
        "\n",
        "    embeddings = HuggingFaceEmbeddings()\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "# Function to perform RAG\n",
        "def perform_rag(vectorstore, query):\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=GROQ_LLM,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=vectorstore.as_retriever()\n",
        "    )\n",
        "    result = qa_chain({\"query\": query})\n",
        "    return result['result']\n",
        "\n"
      ],
      "metadata": {
        "id": "6aWv_LD2QGh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt templates for each node\n",
        "research_topic_prompt = PromptTemplate(\n",
        "    template=\"\"\"Generate a central theme or subject for the research based on the input ideas: {idea_nodes} and the context from relevant papers: {rag_context}\"\"\",\n",
        "    input_variables=[\"idea_nodes\", \"rag_context\"],\n",
        ")\n",
        "\n",
        "idea_node_prompt = PromptTemplate(\n",
        "    template=\"\"\"Generate initial thoughts and concepts related to the research topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "research_question_prompt = PromptTemplate(\n",
        "    template=\"\"\"Generate specific questions that the research aims to address for the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "hypothesis_prompt = PromptTemplate(\n",
        "    template=\"\"\"Propose explanations or predictions that the research will test for the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "literature_prompt = PromptTemplate(\n",
        "    template=\"\"\"Identify key literature and sources that provide background and support for the research topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "methodology_prompt = PromptTemplate(\n",
        "    template=\"\"\"Detail the research methods and approaches to be used for the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "significance_prompt = PromptTemplate(\n",
        "    template=\"\"\"Explain the importance and potential impact of the research on the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "ethical_considerations_prompt = PromptTemplate(\n",
        "    template=\"\"\"Consider ethical issues related to the research on the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "timeline_budget_prompt = PromptTemplate(\n",
        "    template=\"\"\"Plan the research timeline and budget for the topic: {research_topic}\"\"\",\n",
        "    input_variables=[\"research_topic\"],\n",
        ")\n",
        "\n",
        "# Define functions for each node\n",
        "def extract_data_from_documents(state):\n",
        "    print(\"---EXTRACTING DATA FROM DOCUMENTS---\")\n",
        "    file_paths = state['document_paths']\n",
        "    vectorstore = process_documents(file_paths)\n",
        "    query = \" \".join(state['idea_nodes'])\n",
        "    rag_context = perform_rag(vectorstore, query)\n",
        "    return {\"extracted_data\": vectorstore, \"rag_context\": rag_context, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_research_topic(state):\n",
        "    print(\"---GENERATING RESEARCH TOPIC---\")\n",
        "    idea_nodes = state['idea_nodes']\n",
        "    rag_context = state['rag_context']\n",
        "    research_topic = GROQ_LLM.invoke(research_topic_prompt.format(idea_nodes=idea_nodes, rag_context=rag_context))\n",
        "    return {\"research_topic\": research_topic.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_idea_nodes(state):\n",
        "    print(\"---GENERATING IDEA NODES---\")\n",
        "    research_topic = state['research_topic']\n",
        "    idea_nodes = GROQ_LLM.invoke(idea_node_prompt.format(research_topic=research_topic))\n",
        "    return {\"idea_nodes\": idea_nodes.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_research_questions(state):\n",
        "    print(\"---GENERATING RESEARCH QUESTIONS---\")\n",
        "    research_topic = state['research_topic']\n",
        "    research_questions = GROQ_LLM.invoke(research_question_prompt.format(research_topic=research_topic))\n",
        "    return {\"research_questions\": research_questions.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_hypothesis(state):\n",
        "    print(\"---GENERATING HYPOTHESIS---\")\n",
        "    research_topic = state['research_topic']\n",
        "    hypothesis_nodes = GROQ_LLM.invoke(hypothesis_prompt.format(research_topic=research_topic))\n",
        "    return {\"hypothesis_nodes\": hypothesis_nodes.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_literature_review(state):\n",
        "    print(\"---GENERATING LITERATURE REVIEW---\")\n",
        "    research_topic = state['research_topic']\n",
        "    literature_nodes = GROQ_LLM.invoke(literature_prompt.format(research_topic=research_topic))\n",
        "    return {\"literature_nodes\": literature_nodes.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_methodology(state):\n",
        "    print(\"---GENERATING METHODOLOGY---\")\n",
        "    research_topic = state['research_topic']\n",
        "    methodology_nodes = GROQ_LLM.invoke(methodology_prompt.format(research_topic=research_topic))\n",
        "    return {\"methodology_nodes\": methodology_nodes.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_significance(state):\n",
        "    print(\"---GENERATING SIGNIFICANCE---\")\n",
        "    research_topic = state['research_topic']\n",
        "    significance_nodes = GROQ_LLM.invoke(significance_prompt.format(research_topic=research_topic))\n",
        "    return {\"significance_nodes\": significance_nodes.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_ethical_considerations(state):\n",
        "    print(\"---GENERATING ETHICAL CONSIDERATIONS---\")\n",
        "    research_topic = state['research_topic']\n",
        "    ethical_considerations = GROQ_LLM.invoke(ethical_considerations_prompt.format(research_topic=research_topic))\n",
        "    return {\"ethical_considerations\": ethical_considerations.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def generate_timeline_and_budget(state):\n",
        "    print(\"---GENERATING TIMELINE AND BUDGET---\")\n",
        "    research_topic = state['research_topic']\n",
        "    timeline_and_budget = GROQ_LLM.invoke(timeline_budget_prompt.format(research_topic=research_topic))\n",
        "    return {\"timeline_and_budget\": timeline_and_budget.content, \"num_steps\": state['num_steps'] + 1}\n",
        "\n",
        "def compile_final_proposal(state):\n",
        "    print(\"---COMPILING FINAL PROPOSAL---\")\n",
        "    final_proposal = {\n",
        "        \"Research Topic\": state['research_topic'],\n",
        "        \"Ideas\": state['idea_nodes'],\n",
        "        \"Research Questions\": state['research_questions'],\n",
        "        \"Hypothesis\": state['hypothesis_nodes'],\n",
        "        \"Literature\": state['literature_nodes'],\n",
        "        \"Methodology\": state['methodology_nodes'],\n",
        "        \"Significance\": state['significance_nodes'],\n",
        "        \"Ethical Considerations\": state['ethical_considerations'],\n",
        "        \"Timeline and Budget\": state['timeline_and_budget'],\n",
        "    }\n",
        "    return {\"final_proposal\": json.dumps(final_proposal), \"num_steps\": state['num_steps'] + 1}\n",
        "\n"
      ],
      "metadata": {
        "id": "HPb-govyQKnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the workflow\n",
        "workflow = StateGraph(GraphState)\n",
        "workflow.add_node(\"extract_data_from_documents\", extract_data_from_documents)\n",
        "workflow.add_node(\"generate_research_topic\", generate_research_topic)\n",
        "workflow.add_node(\"generate_idea_nodes\", generate_idea_nodes)\n",
        "workflow.add_node(\"generate_research_questions\", generate_research_questions)\n",
        "workflow.add_node(\"generate_hypothesis\", generate_hypothesis)\n",
        "workflow.add_node(\"generate_literature_review\", generate_literature_review)\n",
        "workflow.add_node(\"generate_methodology\", generate_methodology)\n",
        "workflow.add_node(\"generate_significance\", generate_significance)\n",
        "workflow.add_node(\"generate_ethical_considerations\", generate_ethical_considerations)\n",
        "workflow.add_node(\"generate_timeline_and_budget\", generate_timeline_and_budget)\n",
        "workflow.add_node(\"compile_final_proposal\", compile_final_proposal)\n",
        "\n",
        "# Set entry point and define the flow\n",
        "workflow.set_entry_point(\"extract_data_from_documents\")\n",
        "workflow.add_edge(\"extract_data_from_documents\", \"generate_research_topic\")\n",
        "workflow.add_edge(\"generate_research_topic\", \"generate_idea_nodes\")\n",
        "workflow.add_edge(\"generate_idea_nodes\", \"generate_research_questions\")\n",
        "workflow.add_edge(\"generate_research_questions\", \"generate_hypothesis\")\n",
        "workflow.add_edge(\"generate_hypothesis\", \"generate_literature_review\")\n",
        "workflow.add_edge(\"generate_literature_review\", \"generate_methodology\")\n",
        "workflow.add_edge(\"generate_methodology\", \"generate_significance\")\n",
        "workflow.add_edge(\"generate_significance\", \"generate_ethical_considerations\")\n",
        "workflow.add_edge(\"generate_ethical_considerations\", \"generate_timeline_and_budget\")\n",
        "workflow.add_edge(\"generate_timeline_and_budget\", \"compile_final_proposal\")\n",
        "workflow.add_edge(\"compile_final_proposal\", END)\n",
        "\n"
      ],
      "metadata": {
        "id": "gTk2Gjn6QNcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and run the workflow\n",
        "app = workflow.compile()\n",
        "\n",
        "# Example input\n",
        "inputs = {\n",
        "    \"idea_nodes\": [\"Impact of artificial intelligence on education\", \"Personalized learning algorithms\", \"Ethical considerations in AI-driven education\"],\n",
        "    \"document_paths\": [\"path/to/paper1.pdf\", \"path/to/paper2.docx\"],\n",
        "    \"num_steps\": 0\n",
        "}\n",
        "\n",
        "# Run the workflow\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        print(f\"Finished running: {key}: {value}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "LN0XfaMoQPTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final proposal\n",
        "final_state = app.invoke(inputs)\n",
        "print(json.dumps(json.loads(final_state['final_proposal']), indent=2))"
      ],
      "metadata": {
        "id": "-PRESY_9QRMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}